# Qu'est-ce qu'un Syst√®me Distribu√© ?

> **Session 1, Partie 1** - 20 minutes

## Objectifs d'Apprentissage

- [ ] D√©finir ce qu'est un syst√®me distribu√©
- [ ] Identifier les caract√©ristiques cl√©s des syst√®mes distribu√©s
- [ ] Comprendre pourquoi les syst√®mes distribu√©s sont importants
- [ ] Reconna√Ætre les syst√®mes distribu√©s dans la vie quotidienne

## D√©finition

Un **syst√®me distribu√© (distributed system)** est une collection d'ordinateurs ind√©pendants qui appara√Æt √† ses utilisateurs comme un syst√®me coh√©rent unique.

```mermaid
graph TB
    subgraph "Utilisateurs Voient"
        Single["Syst√®me Unique"]
    end

    subgraph "R√©alit√©"
        N1["N≈ìud 1"]
        N2["N≈ìud 2"]
        N3["N≈ìud 3"]
        N4["N≈ìud N"]

        N1 <--> N2
        N2 <--> N3
        N3 <--> N4
        N4 <--> N1
    end

    Single -->|"appara√Æt comme"| N1
    Single -->|"appara√Æt comme"| N2
    Single -->|"appara√Æt comme"| N3
```

### Id√©e Cl√©

La caract√©ristique d√©terminante est l'**illusion d'unit√©** ‚Äî les utilisateurs interagissent avec ce qui semble √™tre un seul syst√®me, tandis qu'en coulisses, plusieurs machines travaillent ensemble.

## Trois Caract√©ristiques Cl√©s

Selon Leslie Lamport, un syst√®me distribu√© est :

> "Un syst√®me dans lequel la d√©faillance d'un ordinateur dont vous ignoriez m√™me l'existence peut rendre votre propre ordinateur inutilisable."

Cette d√©finition met en √©vidence trois caract√©ristiques fondamentales :

### 1. Concurrence (Plusieurs Choses Se Produisent En M√™me Temps)

Plusieurs composants s'ex√©cutent simultan√©ment, entra√Ænant des interactions complexes.

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant A as Serveur A
    participant B as Serveur B
    participant C as Serveur C

    U->>A: Requ√™te
    A->>B: Requ√™te
    A->>C: Mise √† jour
    B-->>A: R√©ponse
    C-->>A: Accus√©
    A-->>U: R√©sultat
```

### 2. Pas d'Horloge Globale

Chaque n≈ìud a sa propre horloge. Il n'y a pas de "maintenant" unique dans le syst√®me.

```mermaid
graph LR
    A[Horloge A : 10:00:01.123]
    B[Horloge B : 10:00:02.456]
    C[Horloge C : 09:59:59.789]

    A -.->|latence r√©seau| B
    B -.->|latence r√©seau| C
    C -.->|latence r√©seau| A
```

**Implication :** Vous ne pouvez pas compter sur les horodatages pour ordonner les √©v√©nements entre les n≈ìuds. Vous avez besoin d'horloges logiques (nous en reparlerons dans les prochaines sessions !).

### 3. D√©faillance Ind√©pendante

Les composants peuvent tomber en panne ind√©pendamment. Lorsqu'une partie tombe en panne, le reste peut continuer ‚Äî ou peut devenir inutilisable.

```mermaid
stateDiagram-v2
    [*] --> TousSains: D√©marrage Syst√®me
    TousSains --> D√©faillancePartielle: Un N≈ìud Tombe en Panne
    TousSains --> D√©faillanceCompl√®te: N≈ìuds Critiques Tombent en Panne
    D√©faillancePartielle --> TousSains: R√©cup√©ration
    D√©faillancePartielle --> D√©faillanceCompl√®te: D√©faillance en Cascade
    D√©faillanceCompl√®te --> [*]
```

## Pourquoi des Syst√®mes Distribu√©s ?

### Extensibilit√©

**Mise √† l'√©chelle Verticale (Scale Up) :**
- Ajouter plus de ressources √† une seule machine
- Finit par atteindre les limites mat√©rielles/co√ªt

**Mise √† l'√©chelle Horizontale (Scale Out) :**
- Ajouter plus de machines au syst√®me
- Potentiel d'extensibilit√© pratiquement illimit√©

```mermaid
graph TB
    subgraph "Mise √† l'√©chelle Verticale"
        Big[Gros Serveur Co√ªteux<br/>100 000 $]
    end

    subgraph "Mise √† l'√©chelle Horizontale"
        S1[Serveur Standard<br/>1 000 $]
        S2[Serveur Standard<br/>1 000 $]
        S3[Serveur Standard<br/>1 000 $]
        S4[...]
    end

    Big <--> S1
    Big <--> S2
    Big <--> S3
```

### Fiabilit√© et Disponibilit√©

Un point unique de d√©faillance est inacceptable pour les services critiques :

```mermaid
graph TB
    subgraph "Syst√®me Unique"
        S[Serveur Unique]
        S -.-> X[‚ùå D√©faillance = Pas de Service]
    end

    subgraph "Syst√®me Distribu√©"
        N1[N≈ìud 1]
        N2[N≈ìud 2]
        N3[N≈ìud 3]

        N1 <--> N2
        N2 <--> N3
        N3 <--> N1

        N1 -.-> X2[‚ùå Un Tombe en Panne]
        X2 --> OK[‚úì Les Autres Continuent]
    end
```

### Latence (Distribution G√©ographique)

Placer les donn√©es plus pr√®s des utilisateurs am√©liore l'exp√©rience :

```mermaid
graph TB
    User[Utilisateur √† New York]

    subgraph "Distribution Globale"
        NYC[Centre de Donn√©es NYC<br/>latence 10ms]
        LON[Centre de Donn√©es Londres<br/>latence 70ms]
        TKY[Centre de Donn√©es Tokyo<br/>latence 150ms]
    end

    User --> NYC
    User -.-> LON
    User -.-> TKY

    NYC <--> LON
    LON <--> TKY
    TKY <--> NYC
```

## Exemples de Syst√®mes Distribu√©s

### Exemples Quotidiens

| Syst√®me | Description | Avantage |
|--------|-------------|---------|
| **Recherche Web** | Serveurs de requ√™tes, serveurs d'index, serveurs de cache | R√©ponses rapides, toujours disponibles |
| **Vid√©o en Streaming** | R√©seaux de diffusion de contenu (CDNs) | Faible latence, haute qualit√© |
| **Achats en Ligne** | Catalogue de produits, panier, paiement, inventaire | G√®re les pics de trafic |
| **R√©seaux Sociaux** | Publications, commentaires, j'aime, notifications | Mises √† jour en temps r√©el |

### Exemples Techniques

**R√©plication de Base de Donn√©es :**
```mermaid
graph LR
    W[√âcrire sur le Primaire] --> P[(DB Primaire)]
    P --> R1[(R√©plique 1)]
    P --> R2[(R√©plique 2)]
    P --> R3[(R√©plique 3)]
    R1 --> Read1[Lire depuis la R√©plique]
    R2 --> Read2[Lire depuis la R√©plique]
    R3 --> Read3[Lire depuis la R√©plique]
```

**R√©partition de Charge :**
```mermaid
graph TB
    Users[Utilisateurs]
    LB[R√©partiteur de Charge]

    Users --> LB
    LB --> S1[Serveur 1]
    LB --> S2[Serveur 2]
    LB --> S3[Serveur 3]
    LB --> S4[Serveur N]
```

## Compromis

Les syst√®mes distribu√©s introduisent de la complexit√© :

| D√©fi | Description |
|-----------|-------------|
| **Probl√®mes R√©seau** | Non fiable, latence variable, partitions |
| **Concurrence** | Conditions de course, interblocages, coordination |
| **D√©faillances Partielles** | Certains composants fonctionnent, d'autres non |
| **Coh√©rence** | Garder les donn√©es synchronis√©es entre les n≈ìuds |

**Le Dilemme Fondamental :**
> "Les avantages de la distribution valent-ils la complexit√© ajout√©e ?"

Pour la plupart des applications modernes, la r√©ponse est **oui** ‚Äî c'est pourquoi nous apprenons ceci !

## R√©sum√©

### Points Cl√©s √† Retenir

1. **Syst√®mes distribu√©s** = plusieurs ordinateurs agissant comme un seul
2. **Trois caract√©ristiques :** concurrence, pas d'horloge globale, d√©faillance ind√©pendante
3. **Avantages :** extensibilit√©, fiabilit√©, latence r√©duite
4. **Co√ªts :** complexit√©, probl√®mes r√©seau, d√©fis de coh√©rence

### V√©rifiez Votre Compr√©hension

- [ ] Pouvez-vous expliquer pourquoi il n'y a pas d'horloge globale dans un syst√®me distribu√© ?
- [ ] Donnez un exemple de syst√®me distribu√© que vous utilisez quotidiennement
- [ ] Pourquoi la d√©faillance ind√©pendante rend-elle les syst√®mes distribu√©s plus difficiles √† construire ?

## üß† Quiz du Chapitre

Testez votre ma√Ætrise de ces concepts ! Ces questions mettront au d√©fi votre compr√©hension et r√©v√©leront les lacunes dans vos connaissances.

{{#quiz ../../quizzes/fundamentals-what-is-ds.toml}}

## Suite

Maintenant que nous comprenons ce que sont les syst√®mes distribu√©s, explorons comment ils communiquent : [Passage de Messages](./02-message-passing.md)
