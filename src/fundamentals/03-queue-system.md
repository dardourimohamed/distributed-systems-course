# Impl√©mentation du Syst√®me de File

> **Session 2** - Session compl√®te (90 minutes)

## Objectifs d'Apprentissage

- [ ] Comprendre le mod√®le producteur-consommateur
- [ ] Construire un syst√®me de file fonctionnel avec des workers concurrents
- [ ] Impl√©menter la tol√©rance aux pannes avec une logique de nouvelle tentative
- [ ] D√©ployer et tester le syst√®me avec Docker Compose

## Le Mod√®le Producteur-Consommateur

Le **mod√®le producteur-consommateur (producer-consumer pattern)** est un mod√®le fondamental des syst√®mes distribu√©s o√π :
- **Les Producteurs** cr√©ent et envoient des t√¢ches √† une file
- **La File** met en tampon les t√¢ches entre les producteurs et les consommateurs
- **Les Workers (consommateurs)** traitent les t√¢ches de la file

```mermaid
graph TB
    subgraph "Producteurs"
        P1[Producteur 1<br/>Serveur API]
        P2[Producteur 2<br/>Planificateur]
        P3[Producteur N<br/>Webhook]
    end

    subgraph "File"
        Q[File de Messages<br/>Tampon de T√¢ches]
    end

    subgraph "Workers"
        W1[Worker 1<br/>Processus]
        W2[Worker 2<br/>Processus]
        W3[Worker 3<br/>Processus]
    end

    P1 --> Q
    P2 --> Q
    P3 --> Q
    Q --> W1
    Q --> W2
    Q --> W3

    style Q fill:#f9f,stroke:#333,stroke-width:4px
```

### Avantages Cl√©s

| Avantage | Explication |
|---------|-------------|
| **D√©couplage** | Les producteurs n'ont pas besoin de conna√Ætre les workers |
| **Mise en Tampon** | La file g√®re les pics de trafic |
| **Extensibilit√©** | Ajoutez/supprimez des workers ind√©pendamment |
| **Fiabilit√©** | Les t√¢ches persistent si les workers tombent en panne |
| **Nouvelle Tentative** | Les t√¢ches √©chou√©es peuvent √™tre remises en file |

## Architecture du Syst√®me

### Vue Compl√®te du Syst√®me

```mermaid
sequenceDiagram
    participant C as Client
    participant P as Producteur
    participant Q as File
    participant W as Worker
    participant DB as Magasin de R√©sultats

    C->>P: HTTP POST /task
    P->>Q: Mettre en File T√¢che
    Q-->>P: ID de T√¢che
    P-->>C: 202 Accept√©

    Note over Q,W: Traitement Asynchrone

    Q->>W: R√©cup√©rer T√¢che
    W->>W: Traiter T√¢che
    W->>DB: Sauvegarder R√©sultat

    W->>Q: Ack (Succ√®s)
    Q->>Q: Supprimer T√¢che
```

### Cycle de Vie d'une T√¢che

```mermaid
stateDiagram-v2
    [*] --> EnAttente: Cr√©ation par le Producteur
    EnAttente --> EnCours: R√©cup√©ration par le Worker
    EnCours --> Termin√©: Succ√®s
    EnCours --> √âchou√©: Erreur
    EnCours --> EnAttente: Nouvelle Tentative
    √âchou√© --> EnAttente: Nombre max de nouvelles tentatives non atteint
    √âchou√© --> LettreMorte: Nombre max de nouvelles tentatives atteint
    Termin√© --> [*]
    LettreMorte --> [*]
```

## Impl√©mentation

### Mod√®les de Donn√©es

**D√©finition de T√¢che :**
```typescript
interface Task {
  id: string;
  type: string;           // 'email', 'image', 'report', etc.
  payload: any;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  createdAt: number;
  retries: number;
  maxRetries: number;
  result?: any;
  error?: string;
}
```

```python
from dataclasses import dataclass, field
from typing import Any, Optional

@dataclass
class Task:
    id: str
    type: str  # 'email', 'image', 'report', etc.
    payload: Any
    status: str = 'pending'  # pending, processing, completed, failed
    created_at: float = field(default_factory=time.time)
    retries: int = 0
    max_retries: int = 3
    result: Optional[Any] = None
    error: Optional[str] = None
```

---

## Impl√©mentation TypeScript

### Structure du Projet
```
queue-system-ts/
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ queue.ts          # Impl√©mentation de la file
‚îÇ   ‚îú‚îÄ‚îÄ producer.ts       # API du producteur
‚îÇ   ‚îú‚îÄ‚îÄ worker.ts         # Impl√©mentation du worker
‚îÇ   ‚îî‚îÄ‚îÄ types.ts          # D√©finitions de types
‚îî‚îÄ‚îÄ Dockerfile
```

### Code TypeScript Complet

**queue-system-ts/src/types.ts**
```typescript
export interface Task {
  id: string;
  type: string;
  payload: any;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  createdAt: number;
  retries: number;
  maxRetries: number;
  result?: any;
  error?: string;
}

export interface QueueMessage {
  task: Task;
  timestamp: number;
}
```

**queue-system-ts/src/queue.ts**
```typescript
import { Task, QueueMessage } from './types';

export class Queue {
  private pending: Task[] = [];
  private processing: Map<string, Task> = new Map();
  private completed: Task[] = [];
  private failed: Task[] = [];

  // Mettre en file une nouvelle t√¢che
  enqueue(type: string, payload: any): string {
    const task: Task = {
      id: this.generateId(),
      type,
      payload,
      status: 'pending',
      createdAt: Date.now(),
      retries: 0,
      maxRetries: 3
    };

    this.pending.push(task);
    console.log(`[Queue] Enqueued task ${task.id} (${type})`);
    return task.id;
  }

  // Obtenir la prochaine t√¢che en attente (pour les workers)
  dequeue(): Task | null {
    if (this.pending.length === 0) return null;

    const task = this.pending.shift()!;
    task.status = 'processing';
    this.processing.set(task.id, task);

    console.log(`[Queue] Dequeued task ${task.id}`);
    return task;
  }

  // Marquer la t√¢che comme termin√©e
  complete(taskId: string, result?: any): void {
    const task = this.processing.get(taskId);
    if (!task) return;

    task.status = 'completed';
    task.result = result;
    this.processing.delete(taskId);
    this.completed.push(task);

    console.log(`[Queue] Completed task ${taskId}`);
  }

  // Marquer la t√¢che comme √©chou√©e (r√©essayer si possible)
  fail(taskId: string, error: string): void {
    const task = this.processing.get(taskId);
    if (!task) return;

    task.retries++;
    task.error = error;

    if (task.retries >= task.maxRetries) {
      task.status = 'failed';
      this.processing.delete(taskId);
      this.failed.push(task);
      console.log(`[Queue] Task ${taskId} failed permanently after ${task.retries} retries`);
    } else {
      task.status = 'pending';
      this.processing.delete(taskId);
      this.pending.push(task);
      console.log(`[Queue] Task ${taskId} failed, retrying (${task.retries}/${task.maxRetries})`);
    }
  }

  // Obtenir les statistiques de la file
  getStats() {
    return {
      pending: this.pending.length,
      processing: this.processing.size,
      completed: this.completed.length,
      failed: this.failed.length
    };
  }

  private generateId(): string {
    return `task-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }
}
```

**queue-system-ts/src/producer.ts**
```typescript
import http from 'http';
import { Queue } from './queue';

const queue = new Queue();

const server = http.createServer((req, res) => {
  if (req.method === 'POST' && req.url === '/task') {
    let body = '';
    req.on('data', chunk => body += chunk);
    req.on('end', () => {
      try {
        const { type, payload } = JSON.parse(body);

        if (!type || !payload) {
          res.writeHead(400);
          res.end(JSON.stringify({ error: 'type and payload required' }));
          return;
        }

        const taskId = queue.enqueue(type, payload);

        res.writeHead(202); // Accepted
        res.end(JSON.stringify({
          taskId,
          message: 'Task enqueued',
          stats: queue.getStats()
        }));
      } catch (error) {
        res.writeHead(400);
        res.end(JSON.stringify({ error: 'Invalid JSON' }));
      }
    });
  } else if (req.method === 'GET' && req.url === '/stats') {
    res.writeHead(200);
    res.end(JSON.stringify(queue.getStats()));
  } else {
    res.writeHead(404);
    res.end(JSON.stringify({ error: 'Not found' }));
  }
});

const PORT = process.env.PORT || 3000;
server.listen(PORT, () => {
  console.log(`Producer API listening on port ${PORT}`);
});

export { queue };
```

**queue-system-ts/src/worker.ts**
```typescript
import http from 'http';
import { Queue, Task } from './types';

// Simuler le traitement de t√¢ches
async function processTask(task: Task): Promise<any> {
  console.log(`[Worker] Processing task ${task.id} (${task.type})`);

  // Simuler le travail
  await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));

  // Simuler des √©chocs occasionnels (20% de chance)
  if (Math.random() < 0.2) {
    throw new Error('Random processing error');
  }

  // Traiter en fonction du type de t√¢che
  switch (task.type) {
    case 'email':
      return { sent: true, to: task.payload.to };
    case 'image':
      return { processed: true, url: task.payload.url };
    case 'report':
      return { generated: true, format: 'pdf' };
    default:
      return { result: 'processed' };
  }
}

class Worker {
  private id: string;
  private queueUrl: string;
  private running: boolean = false;

  constructor(id: string, queueUrl: string) {
    this.id = id;
    this.queueUrl = queueUrl;
  }

  async start(): Promise<void> {
    this.running = true;
    console.log(`[Worker ${this.id}] Started`);

    while (this.running) {
      try {
        await this.processNextTask();
      } catch (error) {
        console.error(`[Worker ${this.id}] Error:`, error);
        await this.sleep(1000); // Attendre avant de r√©essayer
      }
    }
  }

  private async processNextTask(): Promise<void> {
    // R√©cup√©rer la t√¢che de la file
    const task = await this.fetchTask();
    if (!task) {
      await this.sleep(1000); // Pas de t√¢che, attendre
      return;
    }

    try {
      // Traiter la t√¢che
      const result = await processTask(task);

      // Marquer comme termin√©e
      await this.completeTask(task.id, result);
    } catch (error: any) {
      // Marquer comme √©chou√©e
      await this.failTask(task.id, error.message);
    }
  }

  private async fetchTask(): Promise<Task | null> {
    return new Promise((resolve, reject) => {
      http.get(`${this.queueUrl}/dequeue`, (res) => {
        let body = '';
        res.on('data', chunk => body += chunk);
        res.on('end', () => {
          if (res.statusCode === 204) {
            resolve(null); // Aucune t√¢che disponible
          } else if (res.statusCode === 200) {
            resolve(JSON.parse(body));
          } else {
            reject(new Error(`Unexpected status: ${res.statusCode}`));
          }
        });
      }).on('error', reject);
    });
  }

  private async completeTask(taskId: string, result: any): Promise<void> {
    return new Promise((resolve, reject) => {
      const data = JSON.stringify({ result });
      http.request({
        hostname: 'localhost',
        port: 3000,
        path: `/complete/${taskId}`,
        method: 'POST',
        headers: { 'Content-Type': 'application/json', 'Content-Length': data.length }
      }, (res) => {
        if (res.statusCode === 200) {
          resolve();
        } else {
          reject(new Error(`Failed to complete task: ${res.statusCode}`));
        }
      }).on('error', reject).end(data);
    });
  }

  private async failTask(taskId: string, error: string): Promise<void> {
    return new Promise((resolve, reject) => {
      const data = JSON.stringify({ error });
      http.request({
        hostname: 'localhost',
        port: 3000,
        path: `/fail/${taskId}`,
        method: 'POST',
        headers: { 'Content-Type': 'application/json', 'Content-Length': data.length }
      }, (res) => {
        if (res.statusCode === 200) {
          resolve();
        } else {
          reject(new Error(`Failed to fail task: ${res.statusCode}`));
        }
      }).on('error', reject).end(data);
    });
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  stop(): void {
    this.running = false;
  }
}

// D√©marrer le worker
const workerId = process.env.WORKER_ID || 'worker-1';
const worker = new Worker(workerId, 'http://localhost:3000');
worker.start();
```

---

## Impl√©mentation Python

### Structure du Projet
```
queue-system-py/
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ queue.py          # Impl√©mentation de la file
‚îÇ   ‚îú‚îÄ‚îÄ producer.py       # API du producteur
‚îÇ   ‚îî‚îÄ‚îÄ worker.py         # Impl√©mentation du worker
‚îî‚îÄ‚îÄ Dockerfile
```

### Code Python Complet

**queue-system-py/src/queue.py**
```python
import time
import uuid
from dataclasses import dataclass, field
from typing import Any, Optional, List, Dict
from enum import Enum

class TaskStatus(Enum):
    PENDING = 'pending'
    PROCESSING = 'processing'
    COMPLETED = 'completed'
    FAILED = 'failed'

@dataclass
class Task:
    id: str
    type: str
    payload: Any
    status: str = TaskStatus.PENDING.value
    created_at: float = field(default_factory=time.time)
    retries: int = 0
    max_retries: int = 3
    result: Optional[Any] = None
    error: Optional[str] = None

class Queue:
    def __init__(self):
        self.pending: List[Task] = []
        self.processing: Dict[str, Task] = {}
        self.completed: List[Task] = []
        self.failed: List[Task] = []

    def enqueue(self, task_type: str, payload: Any) -> str:
        """Mettre en file une nouvelle t√¢che."""
        task = Task(
            id=f"task-{int(time.time()*1000)}-{uuid.uuid4().hex[:8]}",
            type=task_type,
            payload=payload
        )
        self.pending.append(task)
        print(f"[Queue] Enqueued task {task.id} ({task_type})")
        return task.id

    def dequeue(self) -> Optional[Task]:
        """Obtenir la prochaine t√¢che en attente."""
        if not self.pending:
            return None

        task = self.pending.pop(0)
        task.status = TaskStatus.PROCESSING.value
        self.processing[task.id] = task
        print(f"[Queue] Dequeued task {task.id}")
        return task

    def complete(self, task_id: str, result: Any = None) -> None:
        """Marquer la t√¢che comme termin√©e."""
        task = self.processing.pop(task_id, None)
        if not task:
            return

        task.status = TaskStatus.COMPLETED.value
        task.result = result
        self.completed.append(task)
        print(f"[Queue] Completed task {task_id}")

    def fail(self, task_id: str, error: str) -> None:
        """Marquer la t√¢che comme √©chou√©e (r√©essayer si possible)."""
        task = self.processing.pop(task_id, None)
        if not task:
            return

        task.retries += 1
        task.error = error

        if task.retries >= task.max_retries:
            task.status = TaskStatus.FAILED.value
            self.failed.append(task)
            print(f"[Queue] Task {task_id} failed permanently after {task.retries} retries")
        else:
            task.status = TaskStatus.PENDING.value
            self.pending.append(task)
            print(f"[Queue] Task {task_id} failed, retrying ({task.retries}/{task.max_retries})")

    def get_stats(self) -> Dict[str, int]:
        """Obtenir les statistiques de la file."""
        return {
            'pending': len(self.pending),
            'processing': len(self.processing),
            'completed': len(self.completed),
            'failed': len(self.failed)
        }
```

**queue-system-py/src/producer.py**
```python
from http.server import HTTPServer, BaseHTTPRequestHandler
import json
from queue import Queue

queue = Queue()

class ProducerHandler(BaseHTTPRequestHandler):
    def do_POST(self):
        if self.path == '/task':
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)

            try:
                data = json.loads(post_data.decode())
                task_type = data.get('type')
                payload = data.get('payload')

                if not task_type or not payload:
                    self.send_error(400, 'type and payload required')
                    return

                task_id = queue.enqueue(task_type, payload)

                response = json.dumps({
                    'taskId': task_id,
                    'message': 'Task enqueued',
                    'stats': queue.get_stats()
                })

                self.send_response(202)  # Accepted
                self.send_header('Content-Type', 'application/json')
                self.end_headers()
                self.wfile.write(response.encode())

            except json.JSONDecodeError:
                self.send_error(400, 'Invalid JSON')

    def do_GET(self):
        if self.path == '/stats':
            response = json.dumps(queue.get_stats())
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            self.wfile.write(response.encode())

    def log_message(self, format, *args):
        pass  # Supprimer la journalisation par d√©faut

if __name__ == '__main__':
    import os
    port = int(os.environ.get('PORT', 3000))
    server = HTTPServer(('0.0.0.0', port), ProducerHandler)
    print(f"Producer API listening on port {port}")
    server.serve_forever()
```

**queue-system-py/src/worker.py**
```python
import os
import time
import random
import requests
from typing import Optional, Dict, Any
from queue import Task

# Simuler le traitement de t√¢ches
def process_task(task: Task) -> Any:
    print(f"[Worker] Processing task {task.id} ({task.type})")

    # Simuler le travail
    time.sleep(1 + random.random() * 2)

    # Simuler des √©checs occasionnels (20% de chance)
    if random.random() < 0.2:
        raise Exception('Random processing error')

    # Traiter en fonction du type de t√¢che
    if task.type == 'email':
        return {'sent': True, 'to': task.payload.get('to')}
    elif task.type == 'image':
        return {'processed': True, 'url': task.payload.get('url')}
    elif task.type == 'report':
        return {'generated': True, 'format': 'pdf'}
    else:
        return {'result': 'processed'}

class Worker:
    def __init__(self, worker_id: str, queue_url: str):
        self.id = worker_id
        self.queue_url = queue_url
        self.running = False

    def start(self):
        """D√©marrer la boucle du worker."""
        self.running = True
        print(f"[Worker {self.id}] Started")

        while self.running:
            try:
                self.process_next_task()
            except Exception as e:
                print(f"[Worker {self.id}] Error: {e}")
                time.sleep(1)

    def process_next_task(self):
        """R√©cup√©rer et traiter la prochaine t√¢che."""
        task = self.fetch_task()
        if not task:
            time.sleep(1)  # Pas de t√¢che, attendre
            return

        try:
            result = process_task(task)
            self.complete_task(task['id'], result)
        except Exception as e:
            self.fail_task(task['id'], str(e))

    def fetch_task(self) -> Optional[Dict]:
        """R√©cup√©rer la prochaine t√¢che de la file."""
        try:
            response = requests.get(f"{self.queue_url}/dequeue", timeout=5)
            if response.status_code == 204:
                return None  # Aucune t√¢che
            return response.json()
        except requests.RequestException:
            return None

    def complete_task(self, task_id: str, result: Any):
        """Marquer la t√¢che comme termin√©e."""
        requests.post(
            f"{self.queue_url}/complete/{task_id}",
            json={'result': result},
            timeout=5
        )

    def fail_task(self, task_id: str, error: str):
        """Marquer la t√¢che comme √©chou√©e."""
        requests.post(
            f"{self.queue_url}/fail/{task_id}",
            json={'error': error},
            timeout=5
        )

    def stop(self):
        """Arr√™ter le worker."""
        self.running = False

if __name__ == '__main__':
    worker_id = os.environ.get('WORKER_ID', 'worker-1')
    queue_url = os.environ.get('QUEUE_URL', 'http://localhost:3000')
    worker = Worker(worker_id, queue_url)
    worker.start()
```

---

## Configuration Docker Compose

### Version TypeScript (docker-compose.yml)
```yaml
version: '3.8'

services:
  producer:
    build: ./src
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
    volumes:
      - ./src:/app/src
    command: npm run start:producer

  worker-1:
    build: ./src
    environment:
      - WORKER_ID=worker-1
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: npm run start:worker

  worker-2:
    build: ./src
    environment:
      - WORKER_ID=worker-2
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: npm run start:worker

  worker-3:
    build: ./src
    environment:
      - WORKER_ID=worker-3
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: npm run start:worker
```

### Dockerfile TypeScript
```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./
RUN npm install

COPY . .

CMD ["npm", "run", "start:producer"]
```

### Version Python (docker-compose.yml)
```yaml
version: '3.8'

services:
  producer:
    build: ./src
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
    volumes:
      - ./src:/app/src
    command: python src/producer.py

  worker-1:
    build: ./src
    environment:
      - WORKER_ID=worker-1
      - QUEUE_URL=http://producer:3000
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: python src/worker.py

  worker-2:
    build: ./src
    environment:
      - WORKER_ID=worker-2
      - QUEUE_URL=http://producer:3000
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: python src/worker.py

  worker-3:
    build: ./src
    environment:
      - WORKER_ID=worker-3
      - QUEUE_URL=http://producer:3000
    depends_on:
      - producer
    volumes:
      - ./src:/app/src
    command: python src/worker.py
```

### Dockerfile Python
```dockerfile
FROM python:3.11-alpine

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "src/producer.py"]
```

---

## Ex√©cution de l'Exemple

### √âtape 1 : D√©marrer le Syst√®me

```bash
cd examples/01-queue
docker-compose up --build
```

Vous devriez voir une sortie comme :
```
producer      | Producer API listening on port 3000
worker-1      | [Worker worker-1] Started
worker-2      | [Worker worker-2] Started
worker-3      | [Worker worker-3] Started
```

### √âtape 2 : Soumettre des T√¢ches

Ouvrez un nouveau terminal et soumettez quelques t√¢ches :

```bash
# Soumettre une t√¢che email
curl -X POST http://localhost:3000/task \
  -H "Content-Type: application/json" \
  -d '{"type": "email", "payload": {"to": "user@example.com", "subject": "Hello"}}'

# Soumettre une t√¢che de traitement d'image
curl -X POST http://localhost:3000/task \
  -H "Content-Type: application/json" \
  -d '{"type": "image", "payload": {"url": "https://example.com/image.jpg"}}'

# Soumettre plusieurs t√¢ches
for i in {1..10}; do
  curl -X POST http://localhost:3000/task \
    -H "Content-Type: application/json" \
    -d "{\"type\": \"report\", \"payload\": {\"id\": $i}}"
done
```

### √âtape 3 : Observer le Traitement

Dans les journaux Docker, vous verrez :
```
worker-2      | [Queue] Dequeued task task-1234567890-abc123
worker-2      | [Worker] Processing task task-1234567890-abc123 (report)
worker-2      | [Queue] Completed task task-1234567890-abc123
```

### √âtape 4 : V√©rifier les Statistiques

```bash
curl http://localhost:3000/stats
```

R√©ponse :
```json
{
  "pending": 5,
  "processing": 3,
  "completed": 12,
  "failed": 0
}
```

### √âtape 5 : Tester la Tol√©rance aux Pannes

Arr√™tez un worker :
```bash
docker-compose stop worker-1
```

Les t√¢ches continuent d'√™tre trait√©es par les workers restants. La file g√®re automatiquement la redistribution de la charge.

## Exercices

### Exercice 1 : Ajouter le Support des Priorit√©s

Modifiez la file pour prendre en charge les t√¢ches de priorit√© haute/normale/basse :
1. Ajoutez un champ `priority` au mod√®le de T√¢che
2. Modifiez `enqueue()` pour trier les t√¢ches en attente par priorit√©
3. Testez avec des t√¢ches de priorit√© mixte

### Exercice 2 : Impl√©menter une File des Lettres Mortes

Cr√©ez une file s√©par√©e pour les t√¢ches d√©finitivement √©chou√©es :
1. Ajoutez une file `dead_letter` pour stocker les t√¢ches √©chou√©es
2. Ajoutez un point de terminaison API pour inspecter/r√©essayer les t√¢ches de lettres mortes
3. Journalisez les t√¢ches √©chou√©es dans un fichier pour inspection manuelle

### Exercice 3 : Ajouter la Planification de T√¢ches

Impl√©mentez l'ex√©cution diff√©r√©e des t√¢ches :
1. Ajoutez un horodatage `executeAt` aux t√¢ches
2. Modifiez les workers pour ignorer les t√¢ches planifi√©es dans le futur
3. Utilisez une minuterie/planificateur pour d√©placer les t√¢ches planifi√©es vers la file en attente

## R√©sum√©

### Points Cl√©s √† Retenir

1. **Mod√®le producteur-consommateur** d√©couple la cr√©ation de t√¢ches du traitement
2. **Les files mettent en tampon les t√¢ches** et g√®rent les pics de trafic
3. **Les workers √©voluent ind√©pendamment** des producteurs
4. **La logique de nouvelle tentative** fournit une tol√©rance aux pannes
5. **Docker Compose** permet un d√©ploiement local facile

### V√©rifiez Votre Compr√©hension

- [ ] Comment la file g√®re-t-elle les d√©faillances de workers ?
- [ ] Que se passe-t-il lorsqu'une t√¢che √©choue et que le nombre max de nouvelles tentatives est atteint ?
- [ ] Pourquoi la file est-elle utile pour g√©rer les pics de trafic ?
- [ ] Comment ajouteriez-vous un nouveau type de worker (par exemple, un worker qui traite uniquement les emails) ?

## üß† Quiz du Chapitre

Testez votre ma√Ætrise de ces concepts ! Ces questions mettront au d√©fi votre compr√©hension et r√©v√©leront les lacunes dans vos connaissances.

{{#quiz ../../quizzes/fundamentals-queue-system.toml}}

## Suite

Maintenant que nous avons construit un syst√®me de file, explorons comment partitionner les donn√©es sur plusieurs n≈ìuds : [Partitionnement des Donn√©es](../data-store/01-partitioning.md)
